---
title: "Youtube Trending data analysis."
author: "Neyenhyus, Jan; Ingemey, Sascha"
date : "11.01.2022"
output: html_document
---

## The code setup

First we need to load all the libraries that we use in our functions. We are also reading the source of our data, name it "DE_youtube_trending_data" and use it in future subsets. 

```{r setup, include=FALSE}
library(tidyverse) 
library(dplyr)
library(rjson)
library(tidyjson)
options(scipen = 999)
# Getting the file
DE_youtube_trending_data <- read_csv("YoutubeDataSet/DE_youtube_trending_data.csv")

knitr::opts_chunk$set(echo = TRUE)
```


# The first dataset is the trending videos in germany.

We would like to find out why videos are trending in germany. Its a big goal and therefore we start small.
Firstly, to get a grasp of the most fundamental information we look at the distribution between likes, dislikes and viewcount.
Since there are a lot of videos the graphs seem to be overflowing with datapoints. But it can be noticed that a lot of videos have similiar or close to similar like to dislike ratio. 
Perhaps the category of the video plays a role.

```{r likes to viewcount}
# What is the distribution of likes to view count
# Dislikes to Viewcount?
# Finally what happens between likes and dislikes? How are they distributed


ggplot(data=DE_youtube_trending_data) + geom_point(mapping = aes(x= likes, y= view_count)) 

ggplot(data=DE_youtube_trending_data) + geom_point(mapping = aes(x= dislikes, y= view_count))

ggplot(data=DE_youtube_trending_data) + geom_point(mapping = aes(x= dislikes, y= likes))

# These are really clustered, meaning they are quite a few exceptions. Noteable but to get results we need to look at the cluster more closely


```

# Does the viewcount and category make a difference?

Now we need to find out if the category can make a difference in the popularity of the video.
At first we reduce the number of columns so we have less to compute.
The first graph displays the videos of each category and the amount of views it has gotten. Two categories stand out, 24 and 10, since we can only see a rough outline we create a table. In this table we can see that category 24, 10 and 17 are the top three. Now we can underline these in the graph from before to find some differences.
The biggest difference being category 17 to have a lot of trending videos but low viewcount. If the viewcount isn't a decisive factor then perhaps the category in combination with the tags could be it.

```{r lesssen the amount of columns}
# Lesser Columns
dontNeed <- names(DE_youtube_trending_data) %in% c("publishedAt","trending_date")
droppedTwoColums <- DE_youtube_trending_data[!dontNeed]

# Category in relation to view count? Anything interesting?
ggplot(data=droppedTwoColums) + geom_point(mapping = aes(x= view_count, y= categoryId))

# It looks like two Categories are rather outstanding.
# Number of times a Category Appears
droppedTwoColums %>%
  count(categoryId) %>% 
        arrange(desc(n))

# Category 24 and 10 seem to be the most posted ones. Can we see these in the plot? Nr. 17 is the one with the third most posts
droppedTwoColums %>% 
  ggplot(aes(x= view_count, y= categoryId)) + geom_point(data = droppedTwoColums %>% filter(categoryId == 10), color = "red") + geom_point(data = droppedTwoColums %>% filter(categoryId == 24), color = "green") + geom_point(data = droppedTwoColums %>% filter(categoryId == 17), color = "yellow")

```

# Is there something special about category 10 and 24?

Now we would like to know what these categories actually are. Therefore we import the json file that contains the mapping to the category details.
First we get just the title and the id from the file and then merge it with our dataset so that each row contains the correct categor title.

```{r Json handling and getting the category name}
# Now we can see that indeed. Those with the highest count are also those that are outstanding. But Nr. 17 seems to be quite low for the amount of view count and other categories that weren't posted that often have a higher view count. Is there something special about 10 and 24? And what are these categories anyways?

# Getting just the title and id 
jsondata <- jsonlite::fromJSON("YoutubeDataSet/DE_category_id.json",simplifyDataFrame = TRUE,  flatten = TRUE) 
jsonFrame <- as.data.frame(jsondata)
jsonClipped <-jsonFrame %>% select("items.id","items.snippet.title")
# Actually showing the table of id and title
jsonClipped

## Now we can see that that 24 is entertainment, 10 is music and 17 is Sports.

# Join the two frames together
merged <- merge(droppedTwoColums,jsonClipped, by.x ="categoryId", by.y="items.id")
head(merged)

# Which are the most viewed and posted categories?
jsonCategoryFound <- subset(jsonClipped, jsonClipped$items.id == "10" | jsonClipped$items.id == "24")
#head(jsonCategoryFound)
# Music / Entertainment are the ones!
```

# What are the average views per category?

Since we have the categories added we can find out what the average viewcount is per category to get more insight of the relation to the viewcount.

```{r Average Views per category}
# -> Average views per video, for all
#maybe with errorbars(Standartabweichung)

average <- merged %>% group_by(items.snippet.title) %>% summarise(
  view_count = mean(view_count)
) %>% select(items.snippet.title, view_count)


ggplot(data = average, aes(x = reorder(items.snippet.title, -view_count), y =view_count/1000000, fill = items.snippet.title)) + 
  geom_bar(stat="identity") + 
  scale_y_continuous(limits=c(0, 3), breaks=seq(0, 3, 0.2)) +
  theme(axis.title.x = element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  ylab("Views in 1 Mio") +
  guides(fill=guide_legend(title="Categories"))





```

# Viewcount discovery
Now we can see that music has a giant average viewcount compared to entertainment and sports. 

# Are the tags the major influence?

Since the viewcount isnt that much of an influence, maybe the amount of tags influnce the likely hood that a video appears in the trending page.
```{r Function Count tags}

#unction Count tags
countOfTags <- function(str1){
  resultSplit <- strsplit(str1,split = "\\|")
  return (sapply(resultSplit,length))
}

# Adding the count of tags into the dataframe
merged$Count_Of_Tags <- countOfTags(merged$tags)
head(merged)
# Now we can see that the column Count_Of_Tags has been added to the frame and 

```


# Regression by Sascha Ingemey
```{r Linear Regression Ingemey,Sascha}
#I would like to find the relationship between the number of tags and the view count.
#If the viewcount is in relation to the amount of tags that a video has then it could be save to say that a video that is of lower value can become more "trendy" just by adjusting the description.
# View count being our dependent variable on the independent variable of count of tag (amount of tags that the publisher added).

linearmodel <- lm(merged$view_count ~merged$Count_Of_Tags, data = merged)
summary(linearmodel) # this prints the summary of the regression
```
## Hypothesis
H1 = There is a relationship between the amount of tags and the view count.
H0 = There is no relationship between the amount of tags and the view count.

###Reading the output
When we observe the "Coefficients" part we can see that when a single tag is added to the video it should get around 2226703 views. But it is noteworthy to also look at the error value. This value lays at around 36226 which is quite a high number. Considering that the views per video vary widely it was to be expected to have a high error value. Another remark can be made regarding the actual amount of views that a video can get (seen in the first plots of this document). A lot of videos are scattered between 0 and 5.0e+07 views which is an incredibly high number, with this in mind the error value doesn't seem that big anymore. In my opinion this error values still in the OK range, if it were to go over 100 thousand it would have been a more major impact. Since the videos in this data frame were trending at some point it should be noted that for normal videos the error range would have been more than just major. 

What is even more interesting is that for each tag added it would get less views, to be exact by the amount of 29508. Just with the previous value this also has an error range. The error value is 1610 which is way less than the previous one, but considering the ration of the two numbers ( estimate and error) the error seems to have a bigger influence. I would consider this error range to be more major than the previous one. But this would mean that with each tag more it would become closer to zero and even into the negative which isn't possible in the real world since a video cannot have a negative amount of views. This would also mean that the less tags it has the more views it should get which is surprising. But this also means that the trend is spurious. To predict what the future looks like we would need to also take auto-correclation into account but that is out of scope for this module.

Looking at the Probability, the last two columns, we can see that the the probability of the H0 hypothesis being true is of significant value. It is marked with three asterisks meaning its value is very close to zero. With this I can claim that the relationship between these two variables is not random. There are of course many different variables that could have led to this outcome. One would need to consider the actual content of the video, the way it is presented, if its a category that many people are interested in, if there are tags that are just for meant to be a sort of filler that doesn't even apply to the video and if the content is in relation to newer events of the time. Checking all these variables would go beyond the scope of this analysis and therefore I would like to concentrate on the essence behind it. Can the amount of tags influence the views that a video can get. Obviously this data frame only consists of videos that got to the trending page and therefore all the videos that get published but didn't get so far are neglected. Considering that the amount of videos that are getting uploaded each minute is absolutely huge (Source: https://www.statista.com/statistics/259477/hours-of-video-uploaded-to-youtube-every-minute/ ; 500 hours of videos every minute in Feburary 2020) it wouldn't make for a meaningful analysis.

Looking at the residual standard error we can see that the value of 5905000 with a degree of 83272 in freedom. Meaning that the deviation from the linear model is quite high and a major flaw. But that doesn't have to be that bad. It just shows that the either the deviation of the perfect linear model is quite high or it could be that the linear model is not the correct one to use. There are a lot of graphs that could possibly show the relation better. I am gonna assume that the latter is correct and therefore assume that the relationship between the two variables is not random and not linear. This is further more supported by the R-squared value which is 0.004019. This means that the graph only covers less than 0.005% of the data.

## The Plot Command
```{r Plot command Ingemey,Sascha}
# The plot command generates four different plots that will be analyzed to make more assumptions,disprove or further support the ones we already made.
plot(linearmodel)

```
### Residuals vs Fitted
We can see the red line near the bottom of the graph is very closely to the dotted line indicating that there should be some sort of linearity. Since the data set has such a huge amount of data and its not abnormal for videos to have a much higher value or more precisely it is normal to have a lot of exceptions. This could explain the high error value of the linear model that was previously analysed.

### Normal Q-Q
With this plot we can see if the residuals are distributed normally. If this is the case then the data points would follow or be close to the dotted line. In the graph we can see that they follow the dotted line until around the 1 mark. After this point they slowly increase in value almost looking like an exponential graph. The fact that quite a lot follow the line at first but stray away later on shows that the residuals are not distributed normally.

### Scale Location
This graph is supposed to show that the residuals have equal variance along the regression line (the red line). It is visible that a lot of data points are close to the regression line but its also apparent that quite a lot of points stray away from the line. Especially at the right end it can be seen that a lot of points have a higher residual. The same distance from the line isn't apparent in this graph and therefore the Homoscedasticity has been disproved.

### Residuals vs Leverage
This graph will show if there is data that exerts a lot of influence on the model. Such data would be visible in the top right corner. Looking at the graph we can see that a lot of points are near the regression line which is located closely to the bottom and that quite a few high values are close to the left of the graph. Since there is not a single point near the top right it is safe to assume that there is no data that exerts a lot of influence in this model. 

## Final thoughts
To summarise there is a relationship between the two variables of view count and the amount of tags a video has. It is unclear how the trend would look like in the far future since the count of views regresses with each tag added. There are also a lot of other variables that could cause this for example the content of each video has a huge impact ( topic, setup, presentation etc.). At first i wanted to prove that there is a positive influence on the view count but this has shown that it has the opposite effect. With the help of the plot command i was also able to find out that there the data is not distributed normally, there is no Homoscedasticity and there are no data points that exert a lot of influence on our regression model.


#Regression Done Ingemey,Sascha


#Regression by Jan Neyenhuys

Total like and dislike count to comment count

```{r}
#Add likes to dislikes for the total number of ratings given
merged$Total_Rating <- rowSums(cbind(merged$likes, merged$dislikes))
head(merged)
ratings <- filter(merged, merged$comments_disabled != TRUE & merged$ratings_disabled != TRUE)
#exclude the exceptions in the model
ratingsExclude <- filter(ratings, Total_Rating < 10000000 & Total_Rating > 10000 & comment_count > 1000 & comment_count < 1000000)


```


```{r}
linearmodelRatings <- lm(ratings$Total_Rating ~ratings$comment_count, data = ratings)
summary(linearmodelRatings)

linearmodelRatingsExclude <- lm(ratingsExclude$Total_Rating ~ratingsExclude$comment_count, data = ratingsExclude)

#ggplot(ratings, aes(x=comment_count, y=Total_Rating)) + geom_point() + geom_smooth(method=lm, level=0.95)
```
## Hypothesis
H1 = There is a relationship between the amount of comments and the total amount of ratings given.
H0 = There is no relationship between the amount of comments and the total amount of ratings given.

### Reading the Output

By looking at the "Coefficents" a video with just a single comment should have over 70.000 ratings, which is very unlikely. This number can be so high, because of the exceptions in the model, where a video has a lot of ratings and like no comments. First, i thought to exclude these exceptions to get a better fitting model, but then this wouldn't represent the given model correct. I only excluded the videos where the comments or the rating was disabled. The standard error on this one is with 890 comparatively low to the 70.000 ratings.

With 3.15 ratings per additional comment you can probably say that almost 1/3 of the people that have given a rating also commented something on the video. The standard error with 0.009649 is also comparetively low to the 3.15 estimated.

The statistical significance for the H0 is given by the very low probability that the H0 is true. With this you could say the amount of comments is related to the amount of ratings given. But there are a lot more variables to this relativity, for example the content of this video or the division of the rating between like and dislikes and so on, but i wanted to focus on the comments to ratings relationship, to include both cases, where there are a lot of likes and almost no dislikes and a lot of dislikes but not much likes.

The residual standard error with 252600 is relatively high given the range of ratings between 15 and 16,13 million. This can be duo to the video with a lot of ratings but no comments like i said a the beginning. But i wouldn't say that this would be a big problem and either say that it shows the ratings not only depend on to the amount of comments on the video. That there are a lot of videos that differ from the model can be also said through the R-squared of 0.5677 which says that the model only covers roughly 60% of the data.


```{r}
plot(linearmodelRatings)
plot(linearmodelRatingsExclude)
```
### Residuals vs Fitted
The red line on the model with the exceptions you can see the red line goes almost linear to the top right this could be the cause of the of the exceptions. With an attempt to better show the model i set the range of an other linear model to be the amount of ratings between 10.000 and 10.000.000 and with the comments between 1.000 and 1.000.000. On this "Residuals vs Fitted" model you can see that the red line follows more the path of the dotted line. There for i would project the outcome of the model which exclude these exceptions onto the model with the exceptions and say that it would probably follow the dotted line much more if all these extreme exceptions are excluded.

### Normal Q-Q
In the "Normal Q-Q" you can see that most of the data is normally distributed. The beginning differs a lot a the start but then gets very close to the line. To the end it differs more and more. So you can say that the data is not normally distributed.

### Scale-Location
As you can see most of the data is a the beginning of the graph so and the more you go to the right the less variance shows the graph. You can also see that the variance differs much a the beginning looking a the incline of the red line. So the data shows a lot of variance which explains why the error value was so high. This is probably also of the video with a lot of like and no comments. By looking a the "Scale-Locating of the linear model without the exceptions you can more clearly see that the beginning has a lot of variance and to the end it gets to a linear incline.

### Residuals vs Leverage
By looking at this model you can clearly see a lot influential case at the bottom and some a the top. These are probably the exceptions that i mentioned. But you can also see the a lot of the data of the beginning is drifted to the top which also probably has a impact on the solution. By trying to better linear model i created the linear model with a range of total ratings and amount of comments, so these exceptions probably don't fall into the linear model. This can be seen by the second "Residuals vs Leverage" model where a lot less data is influential.

### Final thoughts
In the end you could say that there is a relation between the amount of comments and the amount of ratings, but as you can see there also a lot of different variables, when it comes to the amount of ratings, shown by the exceptions, and the huge error value. By this regression you can see that a lot more of variables come into play by the amount of ratings than just the comments.
